version: "3.3"
services:

  facetorch-dev:
    platform: linux/amd64
    build:
      context: .
      dockerfile: ./docker/Dockerfile.dev
    volumes:
      - ./:/opt/facetorch
    entrypoint: [ "/bin/bash" ]

  facetorch-dev-gpu:
    build:
      context: .
      dockerfile: ./docker/Dockerfile.dev.gpu
    volumes:
      - ./:/opt/facetorch
    shm_size: 8gb
    runtime: nvidia
    entrypoint: [ "/bin/bash" ]

  facetorch-tests:
    platform: linux/amd64
    build:
      context: .
      dockerfile: ./docker/Dockerfile.tests
    volumes:
      - ./:/opt/facetorch
    entrypoint:
      [
        "conda",
        "run",
        "--no-capture-output",
        "-n",
        "env",
        "pytest",
        "-v",
        "--cov=facetorch",
        "--cov-report=term",
        "--cov-fail-under=95"
      ]

  facetorch-dev-example:
    platform: linux/amd64
    build:
      context: .
      dockerfile: ./docker/Dockerfile.dev
    volumes:
      - ./:/opt/facetorch
    entrypoint:
      [
        "conda",
        "run",
        "--no-capture-output",
        "-n",
        "env",
        "python",
        "scripts/example.py"
      ]

  facetorch-lock:
    platform: linux/amd64
    build:
      context: .
      dockerfile: ./docker/Dockerfile.lock
    volumes:
      - ./:/opt/facetorch
    entrypoint:
      [
        "conda",
        "run",
        "--no-capture-output",
        "-n",
        "base",
        "conda-lock",
        "-p",
        "linux-64",
        "-f",
        "environment.yml",
        "--lockfile",
        "new.conda-lock.yml"
      ]

  facetorch-lock-gpu:
    platform: linux/amd64
    build:
      context: .
      dockerfile: ./docker/Dockerfile.lock
    volumes:
      - ./:/opt/facetorch
    runtime: nvidia
    entrypoint:
      [
        "conda",
        "run",
        "--no-capture-output",
        "-n",
        "base",
        "conda-lock",
        "-p",
        "linux-64",
        "-f",
        "gpu.environment.yml",
        "--lockfile",
        "new.gpu.conda-lock.yml"
      ]
